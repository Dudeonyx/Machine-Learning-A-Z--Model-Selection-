{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FalseScaler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return X\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data( data: str, drop=[], X_slice=slice(0, -1), y_slice=-1, x_label=[], test_size=0.2,\n",
    "        y_label=False, columns_to_encode=[], columns_to_scale=[], scale_y=True, random_state=None, shuffle=True, drop_first=True):\n",
    "    \"\"\"load dataset from csv file and preprocess it\n",
    "\n",
    "    Args:\n",
    "        data (str): path to dataset csv file\n",
    "        drop (list, optional): columns to drop from dataset. Defaults to [].\n",
    "        X_slice (slice, optional): independent variables slice. Defaults to slice(0, -1).\n",
    "        y_slice (int|slice, optional): dependent variables slice. Defaults to -1.\n",
    "        x_label (list, optional): independent variables to be label encoded. Defaults to [].\n",
    "        y_label (bool, optional): label encode dependent variables. Defaults to False.\n",
    "        columns_to_encode (list, optional): columns to get_dummies. Defaults to [].\n",
    "        columns_to_scale (list, optional): columns to normalize. Defaults to [].\n",
    "        scale_y (bool, optional): normalize the dependent variables. Defaults to True.\n",
    "        random_state (int, optional): train test split random state. Defaults to None.\n",
    "        drop_first (bool, optional): drop the first dummy column. Defaults to True.\n",
    "    \"\"\"\n",
    "    raw_dataset = pd.read_csv(data)\n",
    "    dataset = raw_dataset.drop(drop, axis=1)\n",
    "    X = dataset.iloc[:, X_slice]\n",
    "    y = dataset.iloc[:, y_slice].values\n",
    "\n",
    "    # X_label_encoder= ColumnTransformer([('Label',LabelEncoder(), x_labels)], remainder='passthrough')\n",
    "    # X = X_label_encoder.fit_transform(X)\n",
    "\n",
    "    # imputer_embarked  = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    # imputer_age = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "\n",
    "    # X['Embarked'] = imputer_embarked.fit_transform(X['Embarked'].values.reshape(-1,1))\n",
    "    # X['Age'] = imputer_age.fit_transform(X['Age'].values.reshape(-1,1))\n",
    "    X['Embarked'].fillna('unknown', inplace=True)\n",
    "    X['Age'].fillna(29, inplace=True)\n",
    "    # return X\n",
    "    # print(X.isna().sum().sum())\n",
    "    # X = X.dropna(axis=0)\n",
    "\n",
    "    X_label_encoders = {}\n",
    "    y_label_encoder = LabelEncoder()\n",
    "\n",
    "    if x_label != []:\n",
    "        for label in x_label:\n",
    "            X_label_encoders[label] = LabelEncoder()\n",
    "            X_label_encoders[label].fit(X[label])\n",
    "    def X_label_encode(X_new):\n",
    "        X_new = X_new.copy()\n",
    "        if x_label != []:\n",
    "            for label in x_label:\n",
    "                # X_label_encoders[label] = LabelEncoder()\n",
    "                X_new[label] = X_label_encoders[label].transform(X_new[label])\n",
    "        return X_new\n",
    "\n",
    "    X = X_label_encode(X)\n",
    "\n",
    "    # X = X_label_encoder.fit_transform(X)\n",
    "    y_label_encoder.fit(y)\n",
    "\n",
    "    def y_label_encode(y_new):\n",
    "        if y_label:\n",
    "            y_new = y_label_encoder.transform(y_new)\n",
    "            return y_new\n",
    "        else:\n",
    "            return y_new\n",
    "    y = y_label_encode(y)\n",
    "\n",
    "    # column_transformer = ColumnTransformer([('OneHotEncode', OneHotEncoder(drop='first'), columns_to_encode)], remainder='passthrough')\n",
    "    # X = column_transformer.fit_transform(X)\n",
    "    one_hot_encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "    encoded_columns = []\n",
    "    if columns_to_encode != []:\n",
    "        one_hot_encoder.fit(X[columns_to_encode])\n",
    "        encoded_columns = one_hot_encoder.get_feature_names_out()\n",
    "    def get_dummies(X_new):\n",
    "        if columns_to_encode != []:\n",
    "            X_new_dummies = one_hot_encoder.transform(X_new[columns_to_encode]).toarray()\n",
    "            # print(X_dummies.shape)\n",
    "            # print(one_hot_encoder.get_feature_names_out())\n",
    "        #     X_new = pd.get_dummies(\n",
    "            X_new = pd.concat([X_new.drop(columns_to_encode,axis=1), pd.DataFrame(data=X_new_dummies,columns=encoded_columns)], axis=1)\n",
    "        #         X_new, columns=columns_to_encode, drop_first=drop_first)\n",
    "        return X_new\n",
    "    X_dummies = get_dummies(X)\n",
    "\n",
    "\n",
    "    # print(column_transformer\n",
    "    column_order = X_dummies.columns.values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X_dummies,X_dummies,y,y\n",
    "    if test_size > 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_dummies, y, test_size=test_size, random_state=random_state,shuffle=shuffle)\n",
    "\n",
    "    # X_scaler = ColumnTransformer(\n",
    "    #         [('Scaler', StandardScaler(), columns_to_scale)], remainder='passthrough')\n",
    "    # y_scaler = ColumnTransformer([('Scaler', StandardScaler(), scale_y)], remainder='passthrough')\n",
    "    X_scaler = StandardScaler()\n",
    "        \n",
    "    y_scaler = StandardScaler() if scale_y else FalseScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    if columns_to_scale != []:\n",
    "        # print(X_train)\n",
    "        X_train_scaled[columns_to_scale] = X_scaler.fit_transform(X_train[columns_to_scale])\n",
    "    X_train_scaled = X_train_scaled[column_order]\n",
    "    X_test_scaled = X_test.copy()\n",
    "    if columns_to_scale != []:\n",
    "        X_test_scaled[columns_to_scale] = X_scaler.transform(X_test[columns_to_scale])\n",
    "    X_test_scaled = X_test_scaled[column_order]\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "    X_tf_validation, X_tf_test,y_tf_validation, y_tf_test = train_test_split(X_test_scaled,y_test, test_size=0.5)\n",
    "    y_tf_validation = y_scaler.transform(y_tf_validation)\n",
    "\n",
    "    def scaler(X_new):\n",
    "        X_new_scaled = X_new.copy()\n",
    "        if columns_to_scale != []:\n",
    "            X_new_scaled[columns_to_scale] = X_scaler.transform(X_new[columns_to_scale])\n",
    "        return X_new_scaled\n",
    "\n",
    "    def preprocess(path):\n",
    "        X_new_raw = pd.read_csv(path)\n",
    "        X_new = X_new_raw.drop(drop, axis=1)\n",
    "        # X_new2 = X_new_raw.drop(drop, axis=1).reset_index(drop=True)\n",
    "        # print(X_new['Sex'].unique())\n",
    "        X_new['Embarked'].fillna('unknown', inplace=True)\n",
    "        X_new['Age'].fillna(29, inplace=True)\n",
    "        X_new['Fare'].fillna(0, inplace=True)\n",
    "        X_new = X_label_encode(X_new)\n",
    "        X_new = get_dummies(X_new)\n",
    "        # X_new.drop(['SibSp_8'],axis=1)\n",
    "        X_new_scaled = scaler(X_new)\n",
    "        return {\n",
    "            \"X_test\": X_new,\n",
    "            # \"X_test2\": X_new2,\n",
    "            \"X_test_raw\": X_new_raw,\n",
    "            \"X_test_scaled\": X_new_scaled\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"X\":X,\n",
    "        # \"X_raw\":X_raw,\n",
    "        \"X_train\": X_train,\n",
    "        \"X_dummies\": X_dummies,\n",
    "        \"X_train_scaled\": X_train_scaled,\n",
    "        \"X_test\": X_test,\n",
    "        \"X_test_scaled\": X_test_scaled,\n",
    "        \"X_tf_test\": X_tf_test,\n",
    "        \"X_tf_validation\": X_tf_validation,\n",
    "        \"X_scaler\": X_scaler,\n",
    "        # \"X_label_encoder\": X_label_encoder,\n",
    "        \"preprocess\": preprocess,\n",
    "        \"y\":y,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_train_scaled\": y_train_scaled,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_test_scaled\": y_test_scaled,\n",
    "        \"y_tf_test\": y_tf_test,\n",
    "        \"y_tf_validation\": y_tf_validation,\n",
    "        \"y_scaler\": y_scaler,\n",
    "        \"y_label_encoder\": y_label_encoder,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop features: ['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "Categorical: ['Pclass', 'SibSp', 'Parch']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_features = ['PassengerId','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']\n",
    "\n",
    "target_feature = ['Survived']\n",
    "\n",
    "# train_features = ['Pclass','Sex','Age','Fare']\n",
    "train_features = ['Pclass','Sex','Age','SibSp','Parch']\n",
    "\n",
    "\n",
    "drop_features = [feat for feat in all_features if feat not in train_features]\n",
    "\n",
    "numerical_features = ['Age']\n",
    "# numerical_features = ['Age','Fare']\n",
    "\n",
    "label_features = ['Sex']\n",
    "\n",
    "categorical_features = [feat for feat in train_features if feat not in numerical_features+label_features]\n",
    "\n",
    "# categorical_features_no_label = [feat for feat in categorical_features if feat not in label_features]\n",
    "\n",
    "print('Drop features: {}\\nCategorical: {}\\n'.format(drop_features,categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv('train.csv')\n",
    "dataset = raw_dataset\n",
    "X = dataset[train_features]\n",
    "y = dataset[target_feature].values\n",
    "\n",
    "dataset_test = pd.read_csv('test.csv')\n",
    "test_data_raw_raw = dataset_test[dataset_test['Sex']=='male']\n",
    "test_data_raw = test_data_raw_raw[train_features]\n",
    "# test_data_raw.loc[test_data_raw['Parch']==9,'Parch'] = np.nan\n",
    "# test_data_raw.iloc[342]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Sex   Age  SibSp  Parch\n",
       "0         3  male  34.5      0      0\n",
       "2         2  male  62.0      0      0\n",
       "3         3  male  27.0      0      0\n",
       "5         3  male  14.0      0      0\n",
       "7         2  male  26.0      1      1\n",
       "..      ...   ...   ...    ...    ...\n",
       "407       1  male  50.0      1      1\n",
       "413       3  male   NaN      0      0\n",
       "415       3  male  38.5      0      0\n",
       "416       3  male   NaN      0      0\n",
       "417       3  male   NaN      1      1\n",
       "\n",
       "[266 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:170: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction.text import _VectorizerMixin\n",
    "from sklearn.feature_selection._base import SelectorMixin\n",
    "\n",
    "num = make_pipeline(IterativeImputer(max_iter=10, random_state=0),StandardScaler())\n",
    "cat = make_pipeline(SimpleImputer(missing_values=np.nan, strategy='most_frequent'),OneHotEncoder( drop='first',handle_unknown='ignore', sparse=False))\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('Numerical', num, numerical_features),\n",
    "    ('Label', OrdinalEncoder(), label_features), \n",
    "    # ('Fill categorical', SimpleImputer(missing_values=np.nan, strategy='most_frequent'), categorical_features),\n",
    "    ('Categorical', cat, categorical_features),\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_ct = ct.fit_transform(X)\n",
    "\n",
    "test_data = ct.transform(test_data_raw)\n",
    "\n",
    "# print(X_ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_out(estimator, feature_in):\n",
    "    if hasattr(estimator,'get_feature_names'):\n",
    "        if isinstance(estimator, _VectorizerMixin):\n",
    "            # handling all vectorizers\n",
    "            return [f'vec_{f}' \\\n",
    "                for f in estimator.get_feature_names_out()]\n",
    "        else:\n",
    "            return estimator.get_feature_names_out(feature_in)\n",
    "    elif isinstance(estimator, SelectorMixin):\n",
    "        return np.array(feature_in)[estimator.get_support()]\n",
    "    else:\n",
    "        return feature_in\n",
    "\n",
    "\n",
    "def get_ct_feature_names(ct):\n",
    "    # handles all estimators, pipelines inside ColumnTransfomer\n",
    "    # doesn't work when remainder =='passthrough'\n",
    "    # which requires the input column names.\n",
    "    output_features = []\n",
    "\n",
    "    for name, estimator, features in ct.transformers_:\n",
    "        if name!='remainder':\n",
    "            if isinstance(estimator, Pipeline):\n",
    "                current_features = features\n",
    "                for step in estimator:\n",
    "                    current_features = get_feature_out(step, current_features)\n",
    "                features_out = current_features\n",
    "            else:\n",
    "                features_out = get_feature_out(estimator, features)\n",
    "            output_features.extend(features_out)\n",
    "        elif estimator=='passthrough':\n",
    "            output_features.extend(ct.feature_names_in_[features])\n",
    "                \n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.63878901,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.2846632 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.2846632 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.17706291,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_5</th>\n",
       "      <th>SibSp_8</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.207709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-0.823344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.177063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Sex  Pclass_2  Pclass_3  SibSp_1  SibSp_2  SibSp_3  SibSp_4  \\\n",
       "0   -0.592481  1.0       0.0       1.0      1.0      0.0      0.0      0.0   \n",
       "1    0.638789  0.0       0.0       0.0      1.0      0.0      0.0      0.0   \n",
       "2   -0.284663  0.0       0.0       1.0      0.0      0.0      0.0      0.0   \n",
       "3    0.407926  0.0       0.0       0.0      1.0      0.0      0.0      0.0   \n",
       "4    0.407926  1.0       0.0       1.0      0.0      0.0      0.0      0.0   \n",
       "..        ...  ...       ...       ...      ...      ...      ...      ...   \n",
       "886 -0.207709  1.0       1.0       0.0      0.0      0.0      0.0      0.0   \n",
       "887 -0.823344  0.0       0.0       0.0      0.0      0.0      0.0      0.0   \n",
       "888  0.000000  0.0       0.0       1.0      1.0      0.0      0.0      0.0   \n",
       "889 -0.284663  1.0       0.0       0.0      0.0      0.0      0.0      0.0   \n",
       "890  0.177063  1.0       0.0       1.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "     SibSp_5  SibSp_8  Parch_1  Parch_2  Parch_3  Parch_4  Parch_5  Parch_6  \n",
       "0        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "1        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "2        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "3        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "4        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "886      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "887      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "888      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0  \n",
       "889      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "890      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_ct, \n",
    "             columns=get_ct_feature_names(ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266 entries, 0 to 265\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       266 non-null    float64\n",
      " 1   Sex       266 non-null    float64\n",
      " 2   Pclass_2  266 non-null    float64\n",
      " 3   Pclass_3  266 non-null    float64\n",
      " 4   SibSp_1   266 non-null    float64\n",
      " 5   SibSp_2   266 non-null    float64\n",
      " 6   SibSp_3   266 non-null    float64\n",
      " 7   SibSp_4   266 non-null    float64\n",
      " 8   SibSp_5   266 non-null    float64\n",
      " 9   SibSp_8   266 non-null    float64\n",
      " 10  Parch_1   266 non-null    float64\n",
      " 11  Parch_2   266 non-null    float64\n",
      " 12  Parch_3   266 non-null    float64\n",
      " 13  Parch_4   266 non-null    float64\n",
      " 14  Parch_5   266 non-null    float64\n",
      " 15  Parch_6   266 non-null    float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 33.4 KB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(test_data, \n",
    "             columns=get_ct_feature_names(ct)).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ct, y, test_size=0.20, random_state=0)\n",
    "\n",
    "X_test2, X_val, y_test2, y_val = train_test_split(X_test,y_test,test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 16]\n",
      " [24 45]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.776536312849162"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state = 0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\AppData\\Local\\Temp\\ipykernel_33912\\1605166139.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95 15]\n",
      " [20 49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier2 = RandomForestClassifier(n_estimators = 1000,)\n",
    "classifier2.fit(X_train, y_train)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91 19]\n",
      " [22 47]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.770949720670391"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the K-NN model on the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier4 = KNeighborsClassifier(n_neighbors = 21, metric = 'minkowski', p = 2)\n",
    "classifier4.fit(X_train,y_train)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier4.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 12]\n",
      " [22 47]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier3 = SVC(kernel = 'rbf')\n",
    "classifier3.fit(X_train, y_train)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier3.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 14]\n",
      " [22 47]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7988826815642458"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier5 = SVC(kernel = 'linear')\n",
    "classifier5.fit(X_train, y_train)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier5.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 - 7s - loss: 0.6355 - accuracy: 0.6194 - val_loss: 0.5542 - val_accuracy: 0.7556\n",
      "Epoch 2/200\n",
      "15/15 - 3s - loss: 0.5067 - accuracy: 0.7921 - val_loss: 0.4591 - val_accuracy: 0.7889\n",
      "Epoch 3/200\n",
      "15/15 - 3s - loss: 0.4516 - accuracy: 0.8160 - val_loss: 0.4570 - val_accuracy: 0.7556\n",
      "Epoch 4/200\n",
      "15/15 - 3s - loss: 0.4233 - accuracy: 0.8315 - val_loss: 0.4545 - val_accuracy: 0.7667\n",
      "Epoch 5/200\n",
      "15/15 - 3s - loss: 0.4220 - accuracy: 0.8315 - val_loss: 0.5179 - val_accuracy: 0.7667\n",
      "Epoch 6/200\n",
      "15/15 - 3s - loss: 0.4337 - accuracy: 0.8174 - val_loss: 0.4724 - val_accuracy: 0.7667\n",
      "Epoch 7/200\n",
      "15/15 - 5s - loss: 0.4217 - accuracy: 0.8258 - val_loss: 0.5062 - val_accuracy: 0.7556\n",
      "Epoch 8/200\n",
      "15/15 - 2s - loss: 0.4064 - accuracy: 0.8216 - val_loss: 0.4760 - val_accuracy: 0.7556\n",
      "Epoch 9/200\n",
      "15/15 - 3s - loss: 0.3979 - accuracy: 0.8315 - val_loss: 0.4676 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e27b613460>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "input_size = 9\n",
    "\n",
    "max_epochs = 200\n",
    "\n",
    "hidden_layer_size = 1500\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense(input_size,activation='relu'),\n",
    "    # tf.keras.layers.Dense(input_size,activation='sigmoid'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    # # tf.keras.layers.Dense(hidden_layer_size,activation='sigmoid'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    # tf.keras.layers.Dense(2,activation='relu'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size/2,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2,activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=max_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=2,\n",
    "    callbacks=[early_stopper]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 54ms/step - loss: 0.4288 - accuracy: 0.8315\n",
      "Test loss: 0.4288, Accuracy: 83.15%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test2,y_test2)\n",
    "# test_loss, test_accuracy = model.evaluate(data['X_test_scaled'],data['y_test_scaled'])\n",
    "\n",
    "print(f'Test loss: {\"%.4f\"% test_loss}, Accuracy: {\"%.2f\" % (test_accuracy *100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tf_pred_raw = model.predict(test_data)\n",
    "# y_tf_pred_raw = data['y_scaler'].inverse_transform(model.predict(data['X_tf_test']))\n",
    "y_tf_pred = np.array([ [np.argmax(x)] for x in y_tf_pred_raw])\n",
    "y_tf_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tf_pred_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_targets_raw = pd.read_csv('submission_perfect.csv')\n",
    "data_targets = data_targets_raw[data_targets_raw['PassengerId'].isin(test_data_raw_raw['PassengerId'])]['Survived'].values.reshape(-1,1)\n",
    "data_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNeigbors</th>\n",
       "      <th>SVC -rbf</th>\n",
       "      <th>SVC - linear</th>\n",
       "      <th>TensorFlow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.740602</td>\n",
       "      <td>0.808271</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.808271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DecisionTree  RandomForest  KNeigbors  SVC -rbf  SVC - linear  TensorFlow\n",
       "0      0.736842      0.740602   0.808271  0.815789      0.804511    0.808271"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_tf_pred_raw = model.predict(test_data)\n",
    "# y_tf_pred_raw = data['y_scaler'].inverse_transform(model.predict(data['X_tf_test']))\n",
    "y_tf_pred = np.array([ [np.argmax(x)] for x in y_tf_pred_raw])\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"DecisionTree\": [accuracy_score(data_targets,classifier.predict(test_data))],\n",
    "    \"RandomForest\": [accuracy_score(data_targets,classifier2.predict(test_data))],\n",
    "    \"KNeigbors\": [accuracy_score(data_targets,classifier4.predict(test_data))],\n",
    "    \"SVC -rbf\": [accuracy_score(data_targets,classifier3.predict(test_data))],\n",
    "    \"SVC - linear\": [accuracy_score(data_targets,classifier5.predict(test_data))],\n",
    "    \"TensorFlow\": [accuracy_score(data_targets,y_tf_pred)],\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = pd.DataFrame({'PassengerId': dataset_test['PassengerId'], 'Survived': y_tf_pred.ravel()})\n",
    "# output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27f24883858d4a995c2c7f262243d6a3a03dedd87882576a1ad584c8db91620a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TensorFlow26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
