{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FalseScaler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return X\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data( data: str, drop=[], X_slice=slice(0, -1), y_slice=-1, x_label=[], test_size=0.2,\n",
    "        y_label=False, columns_to_encode=[], columns_to_scale=[], scale_y=True, random_state=None, shuffle=True, drop_first=True):\n",
    "    \"\"\"load dataset from csv file and preprocess it\n",
    "\n",
    "    Args:\n",
    "        data (str): path to dataset csv file\n",
    "        drop (list, optional): columns to drop from dataset. Defaults to [].\n",
    "        X_slice (slice, optional): independent variables slice. Defaults to slice(0, -1).\n",
    "        y_slice (int|slice, optional): dependent variables slice. Defaults to -1.\n",
    "        x_label (list, optional): independent variables to be label encoded. Defaults to [].\n",
    "        y_label (bool, optional): label encode dependent variables. Defaults to False.\n",
    "        columns_to_encode (list, optional): columns to get_dummies. Defaults to [].\n",
    "        columns_to_scale (list, optional): columns to normalize. Defaults to [].\n",
    "        scale_y (bool, optional): normalize the dependent variables. Defaults to True.\n",
    "        random_state (int, optional): train test split random state. Defaults to None.\n",
    "        drop_first (bool, optional): drop the first dummy column. Defaults to True.\n",
    "    \"\"\"\n",
    "    raw_dataset = pd.read_csv(data)\n",
    "    dataset = raw_dataset.drop(drop, axis=1)\n",
    "    X = dataset.iloc[:, X_slice]\n",
    "    y = dataset.iloc[:, y_slice].values\n",
    "\n",
    "    # X_label_encoder= ColumnTransformer([('Label',LabelEncoder(), x_labels)], remainder='passthrough')\n",
    "    # X = X_label_encoder.fit_transform(X)\n",
    "\n",
    "    # imputer_embarked  = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    # imputer_age = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "\n",
    "    # X['Embarked'] = imputer_embarked.fit_transform(X['Embarked'].values.reshape(-1,1))\n",
    "    # X['Age'] = imputer_age.fit_transform(X['Age'].values.reshape(-1,1))\n",
    "    X['Embarked'].fillna('unknown', inplace=True)\n",
    "    X['Age'].fillna(29, inplace=True)\n",
    "    # return X\n",
    "    # print(X.isna().sum().sum())\n",
    "    # X = X.dropna(axis=0)\n",
    "\n",
    "    X_label_encoders = {}\n",
    "    y_label_encoder = LabelEncoder()\n",
    "\n",
    "    if x_label != []:\n",
    "        for label in x_label:\n",
    "            X_label_encoders[label] = LabelEncoder()\n",
    "            X_label_encoders[label].fit(X[label])\n",
    "    def X_label_encode(X_new):\n",
    "        X_new = X_new.copy()\n",
    "        if x_label != []:\n",
    "            for label in x_label:\n",
    "                # X_label_encoders[label] = LabelEncoder()\n",
    "                X_new[label] = X_label_encoders[label].transform(X_new[label])\n",
    "        return X_new\n",
    "\n",
    "    X = X_label_encode(X)\n",
    "\n",
    "    # X = X_label_encoder.fit_transform(X)\n",
    "    y_label_encoder.fit(y)\n",
    "\n",
    "    def y_label_encode(y_new):\n",
    "        if y_label:\n",
    "            y_new = y_label_encoder.transform(y_new)\n",
    "            return y_new\n",
    "        else:\n",
    "            return y_new\n",
    "    y = y_label_encode(y)\n",
    "\n",
    "    # column_transformer = ColumnTransformer([('OneHotEncode', OneHotEncoder(drop='first'), columns_to_encode)], remainder='passthrough')\n",
    "    # X = column_transformer.fit_transform(X)\n",
    "    one_hot_encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "    encoded_columns = []\n",
    "    if columns_to_encode != []:\n",
    "        one_hot_encoder.fit(X[columns_to_encode])\n",
    "        encoded_columns = one_hot_encoder.get_feature_names_out()\n",
    "    def get_dummies(X_new):\n",
    "        if columns_to_encode != []:\n",
    "            X_new_dummies = one_hot_encoder.transform(X_new[columns_to_encode]).toarray()\n",
    "            # print(X_dummies.shape)\n",
    "            # print(one_hot_encoder.get_feature_names_out())\n",
    "        #     X_new = pd.get_dummies(\n",
    "            X_new = pd.concat([X_new.drop(columns_to_encode,axis=1), pd.DataFrame(data=X_new_dummies,columns=encoded_columns)], axis=1)\n",
    "        #         X_new, columns=columns_to_encode, drop_first=drop_first)\n",
    "        return X_new\n",
    "    X_dummies = get_dummies(X)\n",
    "\n",
    "\n",
    "    # print(column_transformer\n",
    "    column_order = X_dummies.columns.values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X_dummies,X_dummies,y,y\n",
    "    if test_size > 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_dummies, y, test_size=test_size, random_state=random_state,shuffle=shuffle)\n",
    "\n",
    "    # X_scaler = ColumnTransformer(\n",
    "    #         [('Scaler', StandardScaler(), columns_to_scale)], remainder='passthrough')\n",
    "    # y_scaler = ColumnTransformer([('Scaler', StandardScaler(), scale_y)], remainder='passthrough')\n",
    "    X_scaler = StandardScaler()\n",
    "        \n",
    "    y_scaler = StandardScaler() if scale_y else FalseScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    if columns_to_scale != []:\n",
    "        # print(X_train)\n",
    "        X_train_scaled[columns_to_scale] = X_scaler.fit_transform(X_train[columns_to_scale])\n",
    "    X_train_scaled = X_train_scaled[column_order]\n",
    "    X_test_scaled = X_test.copy()\n",
    "    if columns_to_scale != []:\n",
    "        X_test_scaled[columns_to_scale] = X_scaler.transform(X_test[columns_to_scale])\n",
    "    X_test_scaled = X_test_scaled[column_order]\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "    X_tf_validation, X_tf_test,y_tf_validation, y_tf_test = train_test_split(X_test_scaled,y_test, test_size=0.5)\n",
    "    y_tf_validation = y_scaler.transform(y_tf_validation)\n",
    "\n",
    "    def scaler(X_new):\n",
    "        X_new_scaled = X_new.copy()\n",
    "        if columns_to_scale != []:\n",
    "            X_new_scaled[columns_to_scale] = X_scaler.transform(X_new[columns_to_scale])\n",
    "        return X_new_scaled\n",
    "\n",
    "    def preprocess(path):\n",
    "        X_new_raw = pd.read_csv(path)\n",
    "        X_new = X_new_raw.drop(drop, axis=1)\n",
    "        # X_new2 = X_new_raw.drop(drop, axis=1).reset_index(drop=True)\n",
    "        # print(X_new['Sex'].unique())\n",
    "        X_new['Embarked'].fillna('unknown', inplace=True)\n",
    "        X_new['Age'].fillna(29, inplace=True)\n",
    "        X_new['Fare'].fillna(0, inplace=True)\n",
    "        X_new = X_label_encode(X_new)\n",
    "        X_new = get_dummies(X_new)\n",
    "        # X_new.drop(['SibSp_8'],axis=1)\n",
    "        X_new_scaled = scaler(X_new)\n",
    "        return {\n",
    "            \"X_test\": X_new,\n",
    "            # \"X_test2\": X_new2,\n",
    "            \"X_test_raw\": X_new_raw,\n",
    "            \"X_test_scaled\": X_new_scaled\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"X\":X,\n",
    "        # \"X_raw\":X_raw,\n",
    "        \"X_train\": X_train,\n",
    "        \"X_dummies\": X_dummies,\n",
    "        \"X_train_scaled\": X_train_scaled,\n",
    "        \"X_test\": X_test,\n",
    "        \"X_test_scaled\": X_test_scaled,\n",
    "        \"X_tf_test\": X_tf_test,\n",
    "        \"X_tf_validation\": X_tf_validation,\n",
    "        \"X_scaler\": X_scaler,\n",
    "        # \"X_label_encoder\": X_label_encoder,\n",
    "        \"preprocess\": preprocess,\n",
    "        \"y\":y,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_train_scaled\": y_train_scaled,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_test_scaled\": y_test_scaled,\n",
    "        \"y_tf_test\": y_tf_test,\n",
    "        \"y_tf_validation\": y_tf_validation,\n",
    "        \"y_scaler\": y_scaler,\n",
    "        \"y_label_encoder\": y_label_encoder,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop features: ['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked']\n",
      "Categorical: ['Pclass']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_features = ['PassengerId','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']\n",
    "\n",
    "target_feature = ['Survived']\n",
    "\n",
    "# train_features = ['Pclass','Sex','Age','Fare']\n",
    "train_features = ['Pclass','Sex','Age','Fare']\n",
    "\n",
    "\n",
    "drop_features = [feat for feat in all_features if feat not in train_features]\n",
    "\n",
    "numerical_features = ['Age','Fare']\n",
    "# numerical_features = ['Age','Fare']\n",
    "\n",
    "label_features = ['Sex']\n",
    "\n",
    "categorical_features = [feat for feat in train_features if feat not in numerical_features+label_features]\n",
    "\n",
    "# categorical_features_no_label = [feat for feat in categorical_features if feat not in label_features]\n",
    "\n",
    "print('Drop features: {}\\nCategorical: {}\\n'.format(drop_features,categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv('train.csv')\n",
    "dataset = raw_dataset\n",
    "X_male = dataset[dataset['Sex']=='male'][train_features]\n",
    "y_male = dataset[dataset['Sex']=='male'][target_feature].values\n",
    "X_female = dataset[dataset['Sex']=='female'][train_features]\n",
    "y_female = dataset[dataset['Sex']=='female'][target_feature].values\n",
    "\n",
    "dataset_test = pd.read_csv('test.csv')\n",
    "test_data_raw_male_base = dataset_test[dataset_test['Sex']=='male']\n",
    "test_data_raw_female_base = dataset_test[dataset_test['Sex']=='female']\n",
    "test_data_raw_male = test_data_raw_male_base[train_features]\n",
    "test_data_raw_female = test_data_raw_female_base[train_features]\n",
    "# test_data_raw.loc[test_data_raw['Parch']==9,'Parch'] = np.nan\n",
    "# test_data_raw.iloc[342]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>211.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.3583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Sex   Age      Fare\n",
       "0         3  male  34.5    7.8292\n",
       "2         2  male  62.0    9.6875\n",
       "3         3  male  27.0    8.6625\n",
       "5         3  male  14.0    9.2250\n",
       "7         2  male  26.0   29.0000\n",
       "..      ...   ...   ...       ...\n",
       "407       1  male  50.0  211.5000\n",
       "413       3  male   NaN    8.0500\n",
       "415       3  male  38.5    7.2500\n",
       "416       3  male   NaN    8.0500\n",
       "417       3  male   NaN   22.3583\n",
       "\n",
       "[266 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction.text import _VectorizerMixin\n",
    "from sklearn.feature_selection._base import SelectorMixin\n",
    "\n",
    "num = make_pipeline(IterativeImputer(max_iter=10, random_state=0),StandardScaler())\n",
    "cat = make_pipeline(SimpleImputer(missing_values=np.nan, strategy='most_frequent'),OneHotEncoder( drop='first',handle_unknown='ignore', sparse=False))\n",
    "\n",
    "ct_male = ColumnTransformer([\n",
    "    ('Numerical', num, numerical_features),\n",
    "    ('Label', OrdinalEncoder(), label_features), \n",
    "    # ('Fill categorical', SimpleImputer(missing_values=np.nan, strategy='most_frequent'), categorical_features),\n",
    "    ('Categorical', cat, categorical_features),\n",
    "], remainder='passthrough')\n",
    "ct_female = ColumnTransformer([\n",
    "    ('Numerical', num, numerical_features),\n",
    "    ('Label', OrdinalEncoder(), label_features), \n",
    "    # ('Fill categorical', SimpleImputer(missing_values=np.nan, strategy='most_frequent'), categorical_features),\n",
    "    ('Categorical', cat, categorical_features),\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_ct_male = ct_male.fit_transform(X_male)\n",
    "X_ct_female = ct_female.fit_transform(X_female)\n",
    "\n",
    "test_data_male = ct_male.transform(test_data_raw_male)\n",
    "test_data_female = ct_female.transform(test_data_raw_female)\n",
    "\n",
    "# print(X_ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_out(estimator, feature_in):\n",
    "    if hasattr(estimator,'get_feature_names'):\n",
    "        if isinstance(estimator, _VectorizerMixin):\n",
    "            # handling all vectorizers\n",
    "            return [f'vec_{f}' \\\n",
    "                for f in estimator.get_feature_names_out()]\n",
    "        else:\n",
    "            return estimator.get_feature_names_out(feature_in)\n",
    "    elif isinstance(estimator, SelectorMixin):\n",
    "        return np.array(feature_in)[estimator.get_support()]\n",
    "    else:\n",
    "        return feature_in\n",
    "\n",
    "\n",
    "def get_ct_feature_names(ct):\n",
    "    # handles all estimators, pipelines inside ColumnTransfomer\n",
    "    # doesn't work when remainder =='passthrough'\n",
    "    # which requires the input column names.\n",
    "    output_features = []\n",
    "\n",
    "    for name, estimator, features in ct.transformers_:\n",
    "        if name!='remainder':\n",
    "            if isinstance(estimator, Pipeline):\n",
    "                current_features = features\n",
    "                for step in estimator:\n",
    "                    current_features = get_feature_out(step, current_features)\n",
    "                features_out = current_features\n",
    "            else:\n",
    "                features_out = get_feature_out(estimator, features)\n",
    "            output_features.extend(features_out)\n",
    "        elif estimator=='passthrough':\n",
    "            output_features.extend(ct.feature_names_in_[features])\n",
    "                \n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.669497</td>\n",
       "      <td>-0.423980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.331012</td>\n",
       "      <td>-0.405419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.020785</td>\n",
       "      <td>-0.395945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.793295</td>\n",
       "      <td>0.611092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.208742</td>\n",
       "      <td>-0.103221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>-0.207723</td>\n",
       "      <td>-0.348575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>-0.438610</td>\n",
       "      <td>-0.428620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>-0.284686</td>\n",
       "      <td>-0.290572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>-0.361648</td>\n",
       "      <td>0.103852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.100126</td>\n",
       "      <td>-0.412379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age      Fare  Sex  Pclass_2  Pclass_3\n",
       "0   -0.669497 -0.423980  0.0       0.0       1.0\n",
       "1    0.331012 -0.405419  0.0       0.0       1.0\n",
       "2   -0.020785 -0.395945  0.0       0.0       1.0\n",
       "3    1.793295  0.611092  0.0       0.0       0.0\n",
       "4   -2.208742 -0.103221  0.0       0.0       1.0\n",
       "..        ...       ...  ...       ...       ...\n",
       "572 -0.207723 -0.348575  0.0       1.0       0.0\n",
       "573 -0.438610 -0.428620  0.0       0.0       1.0\n",
       "574 -0.284686 -0.290572  0.0       1.0       0.0\n",
       "575 -0.361648  0.103852  0.0       0.0       0.0\n",
       "576  0.100126 -0.412379  0.0       0.0       1.0\n",
       "\n",
       "[577 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_ct_male, \n",
    "             columns=get_ct_feature_names(ct_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152 entries, 0 to 151\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       152 non-null    float64\n",
      " 1   Fare      152 non-null    float64\n",
      " 2   Sex       152 non-null    float64\n",
      " 3   Pclass_2  152 non-null    float64\n",
      " 4   Pclass_3  152 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 6.1 KB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(test_data_female, \n",
    "             columns=get_ct_feature_names(ct_female)).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_male, X_test_male, y_train_male, y_test_male = train_test_split(X_ct_male, y_male, test_size=0.20, random_state=0)\n",
    "\n",
    "X_test2_male, X_val_male, y_test2_male, y_val_male = train_test_split(X_test_male,y_test_male,test_size=0.5, random_state=0)\n",
    "\n",
    "X_train_female, X_test_female, y_train_female, y_test_female = train_test_split(X_ct_female, y_female, test_size=0.20, random_state=0)\n",
    "\n",
    "X_test2_female, X_val_female, y_test2_female, y_val_female = train_test_split(X_test_female,y_test_female,test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 11]\n",
      " [17 12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7586206896551724"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_male = DecisionTreeClassifier(random_state = 0)\n",
    "classifier_female = DecisionTreeClassifier(random_state = 0)\n",
    "classifier_male.fit(X_train_male,y_train_male)\n",
    "classifier_female.fit(X_train_female,y_train_female)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier_male.predict(X_test_male)\n",
    "cm = confusion_matrix(y_test_male, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test_male, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\AppData\\Local\\Temp\\ipykernel_4716\\364097880.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2_male.fit(X_train_male, y_train_male)\n",
      "C:\\Users\\Dudeonyx\\AppData\\Local\\Temp\\ipykernel_4716\\364097880.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2_female.fit(X_train_female, y_train_female)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80  7]\n",
      " [20  9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7672413793103449"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier2_male = RandomForestClassifier(n_estimators = 1000,)\n",
    "classifier2_male.fit(X_train_male, y_train_male)\n",
    "classifier2_female = RandomForestClassifier(n_estimators = 1000,)\n",
    "classifier2_female.fit(X_train_female, y_train_female)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier2_male.predict(X_test_male)\n",
    "cm = confusion_matrix(y_test_male, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test_male, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  0]\n",
      " [28  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7586206896551724"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the K-NN model on the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier4_male = KNeighborsClassifier(n_neighbors = 21, metric = 'minkowski', p = 2)\n",
    "classifier4_male.fit(X_train_male,y_train_male)\n",
    "classifier4_female = KNeighborsClassifier(n_neighbors = 21, metric = 'minkowski', p = 2)\n",
    "classifier4_female.fit(X_train_female,y_train_female)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier4_male.predict(X_test_male)\n",
    "cm = confusion_matrix(y_test_male, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test_male, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  0]\n",
      " [26  3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7758620689655172"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier3_male = SVC(kernel = 'rbf')\n",
    "classifier3_male.fit(X_train_male, y_train_male)\n",
    "classifier3_female = SVC(kernel = 'rbf')\n",
    "classifier3_female.fit(X_train_female, y_train_female)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier3_male.predict(X_test_male)\n",
    "cm = confusion_matrix(y_test_male, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test_male, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  0]\n",
      " [29  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dudeonyx\\anaconda3\\envs\\TensorFlow26\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier5_male = SVC(kernel = 'linear')\n",
    "classifier5_male.fit(X_train_male, y_train_male)\n",
    "classifier5_female = SVC(kernel = 'linear')\n",
    "classifier5_female.fit(X_train_female, y_train_female)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier5_male.predict(X_test_male)\n",
    "cm = confusion_matrix(y_test_male, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test_male, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 4s - loss: 0.5133 - accuracy: 0.8265 - val_loss: 0.5388 - val_accuracy: 0.7414\n",
      "Epoch 2/200\n",
      "10/10 - 1s - loss: 0.4644 - accuracy: 0.8265 - val_loss: 0.5555 - val_accuracy: 0.7414\n",
      "Epoch 3/200\n",
      "10/10 - 1s - loss: 0.4197 - accuracy: 0.8265 - val_loss: 0.5991 - val_accuracy: 0.7414\n",
      "Epoch 4/200\n",
      "10/10 - 1s - loss: 0.4176 - accuracy: 0.8373 - val_loss: 0.5724 - val_accuracy: 0.7414\n",
      "Epoch 5/200\n",
      "10/10 - 1s - loss: 0.4009 - accuracy: 0.8460 - val_loss: 0.6070 - val_accuracy: 0.7414\n",
      "Epoch 6/200\n",
      "10/10 - 1s - loss: 0.3897 - accuracy: 0.8503 - val_loss: 0.6809 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a6d1c69a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "input_size = 9\n",
    "\n",
    "max_epochs = 200\n",
    "\n",
    "hidden_layer_size = 1500\n",
    "\n",
    "model_male = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense(input_size,activation='relu'),\n",
    "    # tf.keras.layers.Dense(input_size,activation='sigmoid'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    # # tf.keras.layers.Dense(hidden_layer_size,activation='sigmoid'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    # tf.keras.layers.Dense(2,activation='relu'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size/2,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2,activation='softmax'),\n",
    "])\n",
    "\n",
    "model_male.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "model_male.fit(\n",
    "    X_train_male,\n",
    "    y_train_male,\n",
    "    epochs=max_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val_male, y_val_male),\n",
    "    verbose=2,\n",
    "    callbacks=[early_stopper]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 - 3s - loss: 0.7120 - accuracy: 0.7171 - val_loss: 0.6791 - val_accuracy: 0.8438\n",
      "Epoch 2/200\n",
      "6/6 - 1s - loss: 0.6596 - accuracy: 0.7171 - val_loss: 0.5549 - val_accuracy: 0.7500\n",
      "Epoch 3/200\n",
      "6/6 - 1s - loss: 0.5264 - accuracy: 0.7410 - val_loss: 0.4536 - val_accuracy: 0.6562\n",
      "Epoch 4/200\n",
      "6/6 - 1s - loss: 0.4807 - accuracy: 0.7530 - val_loss: 0.4781 - val_accuracy: 0.7188\n",
      "Epoch 5/200\n",
      "6/6 - 1s - loss: 0.4831 - accuracy: 0.6813 - val_loss: 0.4312 - val_accuracy: 0.8750\n",
      "Epoch 6/200\n",
      "6/6 - 1s - loss: 0.4539 - accuracy: 0.7450 - val_loss: 0.4710 - val_accuracy: 0.6562\n",
      "Epoch 7/200\n",
      "6/6 - 1s - loss: 0.4496 - accuracy: 0.7610 - val_loss: 0.4239 - val_accuracy: 0.6562\n",
      "Epoch 8/200\n",
      "6/6 - 1s - loss: 0.4328 - accuracy: 0.7849 - val_loss: 0.3827 - val_accuracy: 0.8438\n",
      "Epoch 9/200\n",
      "6/6 - 2s - loss: 0.4286 - accuracy: 0.7291 - val_loss: 0.4360 - val_accuracy: 0.8750\n",
      "Epoch 10/200\n",
      "6/6 - 1s - loss: 0.4438 - accuracy: 0.7610 - val_loss: 0.4599 - val_accuracy: 0.6562\n",
      "Epoch 11/200\n",
      "6/6 - 1s - loss: 0.4522 - accuracy: 0.7331 - val_loss: 0.5420 - val_accuracy: 0.6562\n",
      "Epoch 12/200\n",
      "6/6 - 1s - loss: 0.4395 - accuracy: 0.7610 - val_loss: 0.5074 - val_accuracy: 0.6562\n",
      "Epoch 13/200\n",
      "6/6 - 1s - loss: 0.4305 - accuracy: 0.7570 - val_loss: 0.4339 - val_accuracy: 0.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a6f694820>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "input_size = 9\n",
    "\n",
    "max_epochs = 200\n",
    "\n",
    "hidden_layer_size = 1500\n",
    "\n",
    "model_female = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense(input_size,activation='relu'),\n",
    "    # tf.keras.layers.Dense(input_size,activation='sigmoid'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    # # tf.keras.layers.Dense(hidden_layer_size,activation='sigmoid'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "    # tf.keras.layers.Dense(2,activation='relu'),\n",
    "    # tf.keras.layers.Dense(hidden_layer_size/2,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2,activation='softmax'),\n",
    "])\n",
    "\n",
    "model_female.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "model_female.fit(\n",
    "    X_train_female,\n",
    "    y_train_female,\n",
    "    epochs=max_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val_female, y_val_female),\n",
    "    verbose=2,\n",
    "    callbacks=[early_stopper]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4523 - accuracy: 0.7931\n",
      "Test loss: 0.4523, Accuracy: 79.31%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_male.evaluate(X_test2_male,y_test2_male)\n",
    "# test_loss, test_accuracy = model.evaluate(data['X_test_scaled'],data['y_test_scaled'])\n",
    "\n",
    "print(f'Test loss: {\"%.4f\"% test_loss}, Accuracy: {\"%.2f\" % (test_accuracy *100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tf_pred_raw = model.predict(test_data)\n",
    "# # y_tf_pred_raw = data['y_scaler'].inverse_transform(model.predict(data['X_tf_test']))\n",
    "# y_tf_pred = np.array([ [np.argmax(x)] for x in y_tf_pred_raw])\n",
    "# y_tf_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tf_pred_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_targets_raw = pd.read_csv('submission_perfect.csv')\n",
    "data_targets_male = data_targets_raw[data_targets_raw['PassengerId'].isin(test_data_raw_male_base['PassengerId'])]['Survived'].values.reshape(-1,1)\n",
    "data_targets_female = data_targets_raw[data_targets_raw['PassengerId'].isin(test_data_raw_female_base['PassengerId'])]['Survived'].values.reshape(-1,1)\n",
    "# data_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNeigbors</th>\n",
       "      <th>SVC -rbf</th>\n",
       "      <th>SVC - linear</th>\n",
       "      <th>TensorFlow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.748120</td>\n",
       "      <td>0.770677</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.796992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.756579</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.723684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DecisionTree  RandomForest  KNeigbors  SVC -rbf  SVC - linear  \\\n",
       "male        0.748120      0.770677   0.812030  0.812030      0.804511   \n",
       "female      0.723684      0.756579   0.697368  0.710526      0.723684   \n",
       "\n",
       "        TensorFlow  \n",
       "male      0.796992  \n",
       "female    0.723684  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_tf_pred_raw_male = model_male.predict(test_data_male)\n",
    "# y_tf_pred_raw = data['y_scaler'].inverse_transform(model.predict(data['X_tf_test']))\n",
    "y_tf_pred_male = np.array([ [np.argmax(x)] for x in y_tf_pred_raw_male])\n",
    "y_tf_pred_raw_female = model_female.predict(test_data_female)\n",
    "# y_tf_pred_raw = data['y_scaler'].inverse_transform(model.predict(data['X_tf_test']))\n",
    "y_tf_pred_female = np.array([ [np.argmax(x)] for x in y_tf_pred_raw_female])\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"DecisionTree\": [accuracy_score(data_targets_male,classifier_male.predict(test_data_male)),accuracy_score(data_targets_female,classifier_female.predict(test_data_female))],\n",
    "    \"RandomForest\": [accuracy_score(data_targets_male,classifier2_male.predict(test_data_male)),accuracy_score(data_targets_female,classifier2_female.predict(test_data_female))],\n",
    "    \"KNeigbors\": [accuracy_score(data_targets_male,classifier4_male.predict(test_data_male)), accuracy_score(data_targets_female,classifier4_female.predict(test_data_female))],\n",
    "    \"SVC -rbf\": [accuracy_score(data_targets_male,classifier3_male.predict(test_data_male)), accuracy_score(data_targets_female,classifier3_female.predict(test_data_female))],\n",
    "    \"SVC - linear\": [accuracy_score(data_targets_male,classifier5_male.predict(test_data_male)), accuracy_score(data_targets_female,classifier5_female.predict(test_data_female))],\n",
    "    \"TensorFlow\": [accuracy_score(data_targets_male,y_tf_pred_male), accuracy_score(data_targets_female,y_tf_pred_female)],\n",
    "}, index=['male', 'female'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = pd.DataFrame({'PassengerId': dataset_test['PassengerId'], 'Survived': y_tf_pred.ravel()})\n",
    "# output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27f24883858d4a995c2c7f262243d6a3a03dedd87882576a1ad584c8db91620a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TensorFlow26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
